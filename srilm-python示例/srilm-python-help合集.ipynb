{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import srilm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module srilm.vocab in srilm:\n",
      "\n",
      "NAME\n",
      "    srilm.vocab - Module dealing with vocabulary\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        Vocab\n",
      "    \n",
      "    class Vocab(builtins.object)\n",
      "     |  A Vocabulary manages a mapping between word string and word index\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __delitem__(...)\n",
      "     |      Remove a word by string or index\n",
      "     |  \n",
      "     |  __getitem__(...)\n",
      "     |      Get the index of a string or the string of an index\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __len__(...)\n",
      "     |      Get the number of words in the vocabulary\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __next__(...)\n",
      "     |      Iterator returns a tuple of (string, index)\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      Add a word with an interned index\n",
      "     |  \n",
      "     |  get(...)\n",
      "     |      Get the index of a string or the string of an index\n",
      "     |  \n",
      "     |  index(...)\n",
      "     |      Map a list of word strings to an array of word indices\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      Read vocabulary from a file\n",
      "     |  \n",
      "     |  remove(...)\n",
      "     |      Remove a word by string or index\n",
      "     |  \n",
      "     |  string(...)\n",
      "     |      Map an array of word indices to a list of word strings\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      Write vocabulary to a file\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  bos\n",
      "     |      Index of the beginning of sentence word '<s>'\n",
      "     |  \n",
      "     |  eos\n",
      "     |      Index of the end of sentence word '</s>'\n",
      "     |  \n",
      "     |  pau\n",
      "     |      Index of the pause-filler word '-pau-'\n",
      "     |  \n",
      "     |  unk\n",
      "     |      Index of the unknown word '<unk>'\n",
      "\n",
      "DATA\n",
      "    __test__ = {}\n",
      "\n",
      "FILE\n",
      "    /Users/yufei/anaconda3/envs/py36/lib/python3.6/site-packages/srilm-2.0.0-py3.6-macosx-10.7-x86_64.egg/srilm/vocab.cpython-36m-darwin.so\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import srilm.vocab\n",
    "help(srilm.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module srilm.ngram in srilm:\n",
      "\n",
      "NAME\n",
      "    srilm.ngram - Module contains garden variety of ngram language models\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        LmIterContext\n",
      "        LmIterProb\n",
      "    srilm.base.Lm(builtins.object)\n",
      "        CacheLm\n",
      "        CountLm\n",
      "        Lm\n",
      "        SimpleClassLm\n",
      "    \n",
      "    class CacheLm(srilm.base.Lm)\n",
      "     |  Unigram cache language model\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CacheLm\n",
      "     |      srilm.base.Lm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  length\n",
      "     |      Length of the cache\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from srilm.base.Lm:\n",
      "     |  \n",
      "     |  prob(...)\n",
      "     |      Compute log probability of p(word | context)\n",
      "     |      \n",
      "     |      Note that the context is an ngram context in reverse order,\n",
      "     |      i.e., if the text is ... w_0 w_1 w_2 ..., then this function computes p(w_2 | w_1, w_0)\n",
      "     |      and 'context' should be (w_1, w_0), *not* (w_0, w_1).\n",
      "     |  \n",
      "     |  prob_ngram(...)\n",
      "     |      Compute log probability of p(ngram[-1] | ngram[-2], ngram[-3], ...)\n",
      "     |      \n",
      "     |      Note that this function takes ngram in its *natural* order.\n",
      "     |  \n",
      "     |  rand_gen(...)\n",
      "     |      Generate a random sentence of word indices from the language model\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      Read the language model from a file\n",
      "     |  \n",
      "     |  serve(...)\n",
      "     |      Start a language model server\n",
      "     |  \n",
      "     |  test(...)\n",
      "     |      Test the language model with ngram counts stored in Stats\n",
      "     |      \n",
      "     |      Returns a tuple of (log_probability, denominator, perplexity)\n",
      "     |  \n",
      "     |  test_counts_file(...)\n",
      "     |      Test the language model with a count file\n",
      "     |      \n",
      "     |      Returns a tuple of (log_probability, denominator, perplexity)\n",
      "     |  \n",
      "     |  test_text_file(...)\n",
      "     |      Test the language model with a text file\n",
      "     |      \n",
      "     |      Returns a tuple of (log_probability, denominator, perplexity)\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      Train the language model\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      Write the language model to a file\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from srilm.base.Lm:\n",
      "     |  \n",
      "     |  debug_level\n",
      "     |      Verbosity level for debugging\n",
      "     |  \n",
      "     |  order\n",
      "     |      Order of the language model\n",
      "     |      \n",
      "     |      Most language models make a Markovian assumption that the predicted word is fully\n",
      "     |      specified by its history/context of length (order-1).\n",
      "     |  \n",
      "     |  running\n",
      "     |      Flag of 'running' mode\n",
      "    \n",
      "    class CountLm(srilm.base.Lm)\n",
      "     |  Ngram language model with deleted interpolation, a.k.a. Jelinek-Mercer smoothing\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CountLm\n",
      "     |      srilm.base.Lm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      Train the Jelinek-Mercer-smoothed ngram language model from ngram counts\n",
      "     |      \n",
      "     |      Note that you *need* to use a different, usually much smaller, heldout ngram counts\n",
      "     |      from the main train ngram counts.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from srilm.base.Lm:\n",
      "     |  \n",
      "     |  prob(...)\n",
      "     |      Compute log probability of p(word | context)\n",
      "     |      \n",
      "     |      Note that the context is an ngram context in reverse order,\n",
      "     |      i.e., if the text is ... w_0 w_1 w_2 ..., then this function computes p(w_2 | w_1, w_0)\n",
      "     |      and 'context' should be (w_1, w_0), *not* (w_0, w_1).\n",
      "     |  \n",
      "     |  prob_ngram(...)\n",
      "     |      Compute log probability of p(ngram[-1] | ngram[-2], ngram[-3], ...)\n",
      "     |      \n",
      "     |      Note that this function takes ngram in its *natural* order.\n",
      "     |  \n",
      "     |  rand_gen(...)\n",
      "     |      Generate a random sentence of word indices from the language model\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      Read the language model from a file\n",
      "     |  \n",
      "     |  serve(...)\n",
      "     |      Start a language model server\n",
      "     |  \n",
      "     |  test(...)\n",
      "     |      Test the language model with ngram counts stored in Stats\n",
      "     |      \n",
      "     |      Returns a tuple of (log_probability, denominator, perplexity)\n",
      "     |  \n",
      "     |  test_counts_file(...)\n",
      "     |      Test the language model with a count file\n",
      "     |      \n",
      "     |      Returns a tuple of (log_probability, denominator, perplexity)\n",
      "     |  \n",
      "     |  test_text_file(...)\n",
      "     |      Test the language model with a text file\n",
      "     |      \n",
      "     |      Returns a tuple of (log_probability, denominator, perplexity)\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      Write the language model to a file\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from srilm.base.Lm:\n",
      "     |  \n",
      "     |  debug_level\n",
      "     |      Verbosity level for debugging\n",
      "     |  \n",
      "     |  order\n",
      "     |      Order of the language model\n",
      "     |      \n",
      "     |      Most language models make a Markovian assumption that the predicted word is fully\n",
      "     |      specified by its history/context of length (order-1).\n",
      "     |  \n",
      "     |  running\n",
      "     |      Flag of 'running' mode\n",
      "    \n",
      "    class Lm(srilm.base.Lm)\n",
      "     |  Ngram language model\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Lm\n",
      "     |      srilm.base.Lm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __len__(...)\n",
      "     |      Get the number of highest order ngram probabilites in the language model\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |  \n",
      "     |  iter(...)\n",
      "     |      Iterate through context/history of certain length\n",
      "     |      \n",
      "     |      Returns a tuple of (array_of_the_context, iterator_for_the_probs_under_this_context)\n",
      "     |  \n",
      "     |  mix_lm(...)\n",
      "     |      Mix a ngram.Lm into this model with weight\n",
      "     |  \n",
      "     |  prune(...)\n",
      "     |      Prune the Ngram language model with Entropy-based pruning, aka, Stolcke pruning\n",
      "     |  \n",
      "     |  set_discount(...)\n",
      "     |      Set the discount object for a specific ngram order\n",
      "     |      \n",
      "     |      Note that in theory, you can even 'mix-and-match' different type of discounts\n",
      "     |      in the same language model.\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      Traint the Ngram language model from ngram counts\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from srilm.base.Lm:\n",
      "     |  \n",
      "     |  prob(...)\n",
      "     |      Compute log probability of p(word | context)\n",
      "     |      \n",
      "     |      Note that the context is an ngram context in reverse order,\n",
      "     |      i.e., if the text is ... w_0 w_1 w_2 ..., then this function computes p(w_2 | w_1, w_0)\n",
      "     |      and 'context' should be (w_1, w_0), *not* (w_0, w_1).\n",
      "     |  \n",
      "     |  prob_ngram(...)\n",
      "     |      Compute log probability of p(ngram[-1] | ngram[-2], ngram[-3], ...)\n",
      "     |      \n",
      "     |      Note that this function takes ngram in its *natural* order.\n",
      "     |  \n",
      "     |  rand_gen(...)\n",
      "     |      Generate a random sentence of word indices from the language model\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      Read the language model from a file\n",
      "     |  \n",
      "     |  serve(...)\n",
      "     |      Start a language model server\n",
      "     |  \n",
      "     |  test(...)\n",
      "     |      Test the language model with ngram counts stored in Stats\n",
      "     |      \n",
      "     |      Returns a tuple of (log_probability, denominator, perplexity)\n",
      "     |  \n",
      "     |  test_counts_file(...)\n",
      "     |      Test the language model with a count file\n",
      "     |      \n",
      "     |      Returns a tuple of (log_probability, denominator, perplexity)\n",
      "     |  \n",
      "     |  test_text_file(...)\n",
      "     |      Test the language model with a text file\n",
      "     |      \n",
      "     |      Returns a tuple of (log_probability, denominator, perplexity)\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      Write the language model to a file\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from srilm.base.Lm:\n",
      "     |  \n",
      "     |  debug_level\n",
      "     |      Verbosity level for debugging\n",
      "     |  \n",
      "     |  order\n",
      "     |      Order of the language model\n",
      "     |      \n",
      "     |      Most language models make a Markovian assumption that the predicted word is fully\n",
      "     |      specified by its history/context of length (order-1).\n",
      "     |  \n",
      "     |  running\n",
      "     |      Flag of 'running' mode\n",
      "    \n",
      "    class LmIterContext(builtins.object)\n",
      "     |  LM context iterator\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __next__(...)\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "    \n",
      "    class LmIterProb(builtins.object)\n",
      "     |  LM probability iterator\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __next__(...)\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "    \n",
      "    class SimpleClassLm(srilm.base.Lm)\n",
      "     |  Simple bigram class-based language model, where a word belongs to a unique class\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SimpleClassLm\n",
      "     |      srilm.base.Lm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |  \n",
      "     |  read_class(...)\n",
      "     |      Read class definition from a file\n",
      "     |      \n",
      "     |      In fact, the file defines a unigram language model of p(w | c).\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      Train the simple class-based language model from bigram class counts and class definition\n",
      "     |  \n",
      "     |  write_class(...)\n",
      "     |      Write class definition to a file\n",
      "     |      \n",
      "     |      In fact, the file defines a unigram language model of p(w | c).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from srilm.base.Lm:\n",
      "     |  \n",
      "     |  prob(...)\n",
      "     |      Compute log probability of p(word | context)\n",
      "     |      \n",
      "     |      Note that the context is an ngram context in reverse order,\n",
      "     |      i.e., if the text is ... w_0 w_1 w_2 ..., then this function computes p(w_2 | w_1, w_0)\n",
      "     |      and 'context' should be (w_1, w_0), *not* (w_0, w_1).\n",
      "     |  \n",
      "     |  prob_ngram(...)\n",
      "     |      Compute log probability of p(ngram[-1] | ngram[-2], ngram[-3], ...)\n",
      "     |      \n",
      "     |      Note that this function takes ngram in its *natural* order.\n",
      "     |  \n",
      "     |  rand_gen(...)\n",
      "     |      Generate a random sentence of word indices from the language model\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      Read the language model from a file\n",
      "     |  \n",
      "     |  serve(...)\n",
      "     |      Start a language model server\n",
      "     |  \n",
      "     |  test(...)\n",
      "     |      Test the language model with ngram counts stored in Stats\n",
      "     |      \n",
      "     |      Returns a tuple of (log_probability, denominator, perplexity)\n",
      "     |  \n",
      "     |  test_counts_file(...)\n",
      "     |      Test the language model with a count file\n",
      "     |      \n",
      "     |      Returns a tuple of (log_probability, denominator, perplexity)\n",
      "     |  \n",
      "     |  test_text_file(...)\n",
      "     |      Test the language model with a text file\n",
      "     |      \n",
      "     |      Returns a tuple of (log_probability, denominator, perplexity)\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      Write the language model to a file\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from srilm.base.Lm:\n",
      "     |  \n",
      "     |  debug_level\n",
      "     |      Verbosity level for debugging\n",
      "     |  \n",
      "     |  order\n",
      "     |      Order of the language model\n",
      "     |      \n",
      "     |      Most language models make a Markovian assumption that the predicted word is fully\n",
      "     |      specified by its history/context of length (order-1).\n",
      "     |  \n",
      "     |  running\n",
      "     |      Flag of 'running' mode\n",
      "\n",
      "DATA\n",
      "    __test__ = {}\n",
      "\n",
      "FILE\n",
      "    /Users/yufei/anaconda3/envs/py36/lib/python3.6/site-packages/srilm-2.0.0-py3.6-macosx-10.7-x86_64.egg/srilm/ngram.cpython-36m-darwin.so\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import srilm.ngram\n",
    "help(srilm.ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module srilm.stats in srilm:\n",
      "\n",
      "NAME\n",
      "    srilm.stats - Module for dealing with ngram counts\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        Stats\n",
      "        StatsIter\n",
      "    \n",
      "    class Stats(builtins.object)\n",
      "     |  Ngram counts stored in a trie\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __delitem__(...)\n",
      "     |      Remove an ngram\n",
      "     |  \n",
      "     |  __getitem__(...)\n",
      "     |      Get the count of an ngram\n",
      "     |  \n",
      "     |  __iter__(...)\n",
      "     |      Iterate through ngrams of the highest order\n",
      "     |  \n",
      "     |  __len__(...)\n",
      "     |      Get the total count of ngrams of the highest order\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |  \n",
      "     |  __setitem__(...)\n",
      "     |      Set the count of an ngram\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      Increase the count of an ngram\n",
      "     |  \n",
      "     |  copy(...)\n",
      "     |      Return a copy of self\n",
      "     |  \n",
      "     |  count(...)\n",
      "     |      Count an array of indices\n",
      "     |  \n",
      "     |  count_file(...)\n",
      "     |      Count a text file\n",
      "     |  \n",
      "     |  count_string(...)\n",
      "     |      Count a list of strings\n",
      "     |  \n",
      "     |  iter(...)\n",
      "     |      Iterate through ngrams of a certain order\n",
      "     |  \n",
      "     |  make_test(...)\n",
      "     |      Prepare for testing by stripping away unnecessary counts\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      Read counts from a file\n",
      "     |  \n",
      "     |  remove(...)\n",
      "     |      Remove an ngram\n",
      "     |  \n",
      "     |  sum_counts(...)\n",
      "     |      Recompute lowerer order counts by summing higher order counts\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      Write counts to a file\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  order\n",
      "     |      Ngram order of the counts\n",
      "    \n",
      "    class StatsIter(builtins.object)\n",
      "     |  Ngram stats iterator\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __next__(...)\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "\n",
      "DATA\n",
      "    __test__ = {}\n",
      "\n",
      "FILE\n",
      "    /Users/yufei/anaconda3/envs/py36/lib/python3.6/site-packages/srilm-2.0.0-py3.6-macosx-10.7-x86_64.egg/srilm/stats.cpython-36m-darwin.so\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import srilm.stats\n",
    "help(srilm.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module srilm.discount in srilm:\n",
      "\n",
      "NAME\n",
      "    srilm.discount - Module contains garden variety of ngram discounting methods\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        Discount\n",
      "    \n",
      "    class Discount(builtins.object)\n",
      "     |  Hold parameters for Ngram discount/smoothing method\n",
      "     |  \n",
      "     |  Note that you need one Discount() obj for each ngram order. If Discount.discount\n",
      "     |  is provided, it will be used in Lm.train(); otherwise, it will be set with the\n",
      "     |  estimated value.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |  \n",
      "     |  estimate(...)\n",
      "     |      Estimate the discount value from ngram counts Stats\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      Read discount from a file\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      Write discount to a file\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  discount\n",
      "     |  \n",
      "     |  interpolate\n",
      "     |  \n",
      "     |  max_count\n",
      "     |  \n",
      "     |  method\n",
      "     |  \n",
      "     |  min_count\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "\n",
      "DATA\n",
      "    __test__ = {}\n",
      "\n",
      "FILE\n",
      "    /Users/yufei/anaconda3/envs/py36/lib/python3.6/site-packages/srilm-2.0.0-py3.6-macosx-10.7-x86_64.egg/srilm/discount.cpython-36m-darwin.so\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import srilm.discount\n",
    "help(srilm.discount)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
